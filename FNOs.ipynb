{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FNOs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# The Fourier Neural Operator method in JAX"
      ],
      "metadata": {
        "id": "cIfsZ97kgfL0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How does the Fourier Neural Operator method work\n",
        "\n",
        "![FNO.jpg](data:image/jpeg;base64,/9j/4AAQSkZJRgABAgAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCADAAhADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD3+iiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiub8YXjpZ2+mxMVe+crIR1ESjL4Pv8q/8AAqcU5OyE3ZXK994rmuJWi0aOJolODeTAlGPfYoILfXIHpms7+0NcPJ1uYN6C3h2/lsz+tRKFRQiAKqjAA7CoYbtJ57iNAdsDBWftuxkj8AR+delHD04qz1OSVWTehq2vi28sGA1iOOW16G7t0IKe7pzx7j8q7GORJoklidXjcBlZTkEHoQa84u7uO1iV5BmJnCOey7uAT7ZI/OtjwbdNaXt1ojEmFU+02ox91ScOufQEgj/ermr0FD3om1Ko5aM7GignAyelVNTvRp2l3F5gMYkJVc/eboB+JwK5W7GyVyjq/iCHTX+zwx/aLsjPlhsBB6se3061z8mu6zK243iQj+7DCuP/AB7NZ0asNzyuXmkJeRz1Zj1NR3V5b2UavcSCNWYIpIPLHoK8Otjqk5Wg7I9mlg6cI3nqzatvEuqWzDzxFeR9xt8t/wACOD9MD611Wn6jbanai4tnJXO1lIwyN3BHY159BPFcwrNBIskbfdZTkGr2k3jadrMEoOIrhlgmHY5OEP1DED6E1rhcbPnUKnUzxOEhyudPod7SM21Cx7DNLTJSDDJz0U/yr1zyjBt/EN9dW0VxFormOVA65uEBwRkVL/bWpf8AQEb/AMCUrP0zUrGz0PTY7q9t4HNnEwWWVVONo5wT0rZrz3iaiZVkVv7a1L/oCN/4EpR/bWpf9ARv/AlKs01JEkLhHVih2sAc7TjOD6HBH50fWphZEH9tal/0BG/8CUo/trUv+gI3/gSlWajhnhuAxhkSQKxRipzhh1B9xR9ZqBZEX9tal/0BG/8AAlKP7a1L/oCN/wCBKVZopfWphZFb+2tS/wCgI3/gSlT6Zq8l9fXNnPZPbTQRxy4MgcMrlgOnuhpJJY4tvmSKm5gq7jjJPQD3qtpv/I2al/1423/oc9bUa8pyswaN+sH/AISC5kubqK10p5kt5jCXMyrkjGcA/Wt6uSsby1s5dUa6uYYFbUZVUyuFBOBwM1rWm4RuhI0f7a1L/oCN/wCBKUf21qX/AEBG/wDAlKlhniuYVlglSWNvuujBgfoRUlcv1qoOyK39tal/0BG/8CUo/trUv+gI3/gSlT+YnmeXvXfjdtzzj1xTqPrUwsit/bWpf9ARv/AlKP7a1L/oCN/4EpUoniad4BIplRQzJnkA5wcehwfyqSj61UCyK39tal/0BG/8CUo/trUv+gI3/gSlWajnuIbWIy3E0cUY6tIwUfmaPrNQLIjg16dtTtbK6017c3O4I/mqwyqlucewrbrmJ5El8Q6BJG6ujPMVZTkEeUeQa6euujNzjdiYUUUVqIKKKKACiiigArO1q/m06wWa3jR5XmjiUSEhfncLk4+taNY3ib/kHW//AF+23/o1amTtFsBn2zXP+een/m9H2zXP+een/m9Qw61YT3jWsUzNKsrQn90+0OoyV3YxnHPWr9ef9YqLqXZFb7Zrn/PPT/zej7Zrn/PPT/zerDMFUsegGTSRyLNEkiElHUMpIxwfY0fWKncLIg+2a5/zz0/83o+2a5/zz0/83qS5uI7O1muZiRFChdyATgAZPAp6OskayIcqwBB9jR9YqdwsiD7Zrn/PPT/zej7Zrn/PPT/zerNFH1ip3CyK32zXP+een/m9W9E1CXU9MFxNGkcommhZUJIzHK0eRn125/GshfEmlNdfZhct5u8JjyXxkvsHOMfeBGc4zV3wp/yBZP8Ar/vf/SmWuihUnJtSE0bdR3FxDa27zzyLHFGNzMx4AqTIzjPNcd4ovDc6mlgD+5t1Ekg7NIfug/Qc/wDAge1a1qqpQc2VSpupNRQt34qvLhiLCJLeHtJMu529wvRfxz9BVRdb1lDuGoBz/dkhTb+gB/WqdVhqNo119mFwhmyV2/7QGSM9M45x1rxJYyvJ3TPZjhKMVZo67S/E4nmS21CNYJnO1JUP7tz2HPKk+h/PPFdFXm0iLLGyOMqwwRXY+Gr+S+0rbO5ee3cwyMerYAIJ9ypGffNejg8U6t4z3R5+Lwype9HY2Kp6nqdrpNmbm6chc7VVRlnY9FUdyauZGcZ5rg9UujqfiC5lY5hs2NvAOwYY8xvrn5fovvXp0qfPLlOCcuVXJbjX9avWzE8WnRfwqiCWT8WPyj6AH6mol1PXoWDx6t5xH8FzboVP/fAU/rVW6uo7S3aZ+QpAAHUknAH1JIFShsgE8EjpXoLD07Wscjqz3udDoviiPULkWF7D9k1DblU3ZSUDqUbv9DyK6CvL5wuoCaKMmK7tZA0b90fqrD2rvtA1M6vodresu2SRMSL6ODhh+YNcVel7N6bHTTnzLU0q5Hxcdus6QT0aO4QH3/dn+SmuurI8R6U+raXsgIW7gcTW5PTeM8H2IJH41nTlyyTKkrxaPLLyz1VNWuGggnkhluoX3CYBfLTLdzkZc4PH3QOtTxC4jsL6CO1e5mW+cvGsgQlWO4HJ6jBH5YrdtrhbhCdrJIh2yROMNGw6qR61IEQOXCqHYAFsckV6iinqmcTb2ZyY0+e18F3VvMky3k8CQ/vZd5aYqFBHJx8x9a6zTYri58WwR2l2baSOzld2CBsqWQAYPuM/hUV1LbwQ+fcbQsZyCwyQenHvziui8I6VPbRXGp3sZjur3biJusUQ+6p9+ST9fasMS1GHL3NaSblcuy6fqpicHV2cbTlfs0fze1cVo/hzxLoHgy4TXdaN4m+No7TbuFuokU48w8nA/AV6bUVzbx3drLbTLuilQo49QRg15so80Wjsi+VpnntZOrWlze32mxxGSOGOVppJU2/KQhCjB9S3p2rXmt5rC6ayus+an3XI4lXsw/qOx/Ckr5pxlTk01qj6FONSN1sV7KzisLOO2hzsTPLHJJJySfckk1LIrO0KJ99po1X6lxin1p+HNPa/v479lP2S3JMZ7SydMj1A5/H6VphqcqlVWM8RONOk7m/9g1b/AKDTf+AyVyd54X8Vy+ODqlt4ga109LZUnHlKftLDJxs6DAIG4816DTJv9TJ/un+VfRngHm0enXV9qWiiImOA6II5ZGg3owLxEoSeASoalmuPELQ3BiF2LlYL0zKEIUOH/ceXngkr6de/NdTof/IA03/r1i/9AFX68pz1LOMku9TvbsrG2oxW0uqxqrCJkIt2thnqOB5mevQ+lMnk1e1llhR7sWv9oMkk/kO7lPIUK3yjJG/PI7j0rtqKXP5Ac5o0OoyaxcG9vLtltlh2ZTy45SYsOcY/vc4zwaxtSn1K2sNTjsYNQS4knvJIGijYAuACnRecnpkhTg5zwK7yihT1uBxd5NrhudXgsZp3kto2vLc9d2+PCREH0cSHHsvrTkXU7qWwiF/qH2a5uZAzpA8TRR+TwCWGR84yCcdcdK6y3tLa08z7NBFD5rmR/LQLuc9WOOpPrU1HP5Ac34tgDro7rbyTSxajA+5IWcogYFjwDgYq7ANQPiy/+wtbKPsNtu89GP8AHNjGCK16p6b/AMjZqX/Xjbf+hz1thn76QmUPFa+Kv+EZvf7Pktze7R9n+zRuH8zI24JbGM9c8YzmuVsYNdn0axTVAn9rrrm65e3jLoh2kFsdMcjPbJr1iuZ0j/X6t/2EJf5CujEu0LiRhCPVrG6FojTmSOW2ERhi2wyoSDO7Y4BJLnnnpis64v8AxD9iuUiGoieLTb1c+S3Nwsq+Vjjk7ScY4Ir0GiuHn8ijj9V/tSwkuRp73k7G3jfzJIy5AM/7wA46hCcL144qS2TUZ9S06GS+vjayRXMjSLE8eCJIzGrbhkYG8DOCQK6yijmA5bV5bi1129uI7e7dHtLWLfAjf89pN3IUngMCcDOD+NZ1jNrcj6dBNPdhrxZYH35VofKmzvwefmj4z67fWu6qFbS2W7e7W3iFy6hGlCDeyjoCeuKFPTYDjEn11tPvJpLm8W4QBXhW2fKv5wwUPIYbcj5QRjrzW9q8h0jR49sNxfTLLiJ2iadoy2fnIAzhQT+g71t0UOVwOUs7drYeF4NLVoxGZVQXsbBseW2Sy8EE9fxrqSuvY5l03/v0/wD8VWfdf8jLoX/XSb/0U1dLXfh3eBLOH8ADxqFuP+Eia3On72+yeYD9p2Z+Xd7Yx1y3rXOfHS88V2ml6Z/wjxvUtmkf7U9nu3huNgJXkD734163RjPWtxHJeCp/EUvw2spdWRv7cNs5xMMMTlvL3+5G3NeY/CDUPH1z48vI9cOpNY+W5uheKwVH/h254Bz2Have6MUAeJ/HK+8Z2uq6SugNqKaeY8lrINkzbjw23nptwD716joj63L4S0x7zyk1ZraM3AmUkB9o3ZAI5rbxmigDKK69g5k03H/XJ/8A4quD0geNRpx/4SE2/wDZ39ow/ZPMB+07POXbu7Yx65PrXqNY3ib/AJB1v/1+23/o1amfwsaOSXw/qfk+IJopLiG4uLidrePzgEdWCYbjoflIz2zTxpeow30d1DZP9lGoF1tPMUFImtjGeM4wZPmwD79eK7CivL52UcPpPh+9EMH9o2kjSQ6PbwgmUHNwgcN35PI5PWpbDRtT+12RvkuSI7e12NHImI2RcSI2Tn5j1xnIPbFdnRRzsDldL0Se08Ez2z2zDUp7N4pFMm4s2GC85x3qje2F62oW1xe2wttPgbFzOZlAMBtWVtx3cYcjgAD5Q3JruKCARg8ijnYHBWek6jcaZp926POC4jmSErmWFI2RHAbg5b5/xHoK2tI0V7fV5JrmOZxFBbrBNLLuLOqMrk4PXBAJxzXR0UObYGMtlMPF8l39n/0U2KRCTIxvEjNjGc9wc4pfDtnqMumTvDqhhjN/eYj8hWx/pMvc1sVX8Kf8gWT/AK/73/0plrpwrvJiZz3i/wAMeKdXk0oaVrxt54LgyPd+Wq+Um3BGB97JI4PHHNV7uG4ttVvIbuc3FwDGWmKBPM/dqN2BwOQR+FeiVzPinTZGZNTt0LtGmydFGSyZyCB3Kknj0Jq8ZTdSk1Hc3wlRQqps56uR0iFpbnTtOmXy7jTma4ud7DdJKwYZXnJU72OfoPXHWo6yIHRgykZBB4NGBu3YGfWvBjLlTR7co8zTFrT8NWl/M+oy22otbxecq7fJVuQgzyfqKyiXaRIYUMs8hxHGvVj/AEHqe1d1o+nDS9MjtiwaTl5XH8Tnkn6dh7AV6GXU3zufQ4cwqLlUOpynjHw14n1e20+LStcMNzFdrL9p8tU8lQpBPy8tnONvQ96ybVbqztL6GVjeX1vPOHYgIZpNxbOOi7sg+2a9Qri/E1i2m6m2rKCbO5Crckf8snAwHPsRgH0wK9/DzUZ6ni1Ytx0OBt7DULSy8y+keRFvYGy/3inHJGSOGbrx06CrmoWl5e64ubW7W1TcDJHcABz8m3jPAHzdq6RlWRCrAMjDkHkEU4AAAAYA7CvR5FscnMZtp82u37L9xYYIz/vDeT+jLXWeBAT4cMo+5LczSR/7pc1zMqSXM40vTUH2y55YqOIlPWRv6epr0PT7KLTdPt7KAYigQIvvjvXHipLSKOiinuWaKKK4zcyNU8OWOqSi4bzLe7AwLiAhWI9DkEMPqDWQfCOojhdZiK+rWeW/MOB+lddRVxqSjsyXGL3Rhab4VsrK4S6uJJb26TlJJ8YQ/wCyoAA+vX3rdooqW23djStsFFFFIZVvtOtdSg8m7hEig5U9Cp9QRyD9KwpPCADEwajMF7LKivj8Rg/nXT0VnOlCp8SuaQqzh8Lsc7b+ELRW3Xk812M58t8Kn4gAZHsc10KIsaBEUKqjAAGABS0U4U4wVoqxM5ym7ydwpGXchU9xiloqyTAtvD13a2sVvFrNwI4kCLmGM8AYH8NS/wBi33/Qan/78x//ABNbVFZ+yh2HdmL/AGLff9Bqf/vzH/8AE0f2Lff9Bqf/AL8x/wDxNbVBIAJJwB3NHsodguzF/sW+/wCg1P8A9+Y//iaP7Fvv+g1P/wB+Y/8A4mtCXUbSEurTBmR1R1jBdlLdAQuSM+9J9rmdiIrOU7ZvLYuQo292HqKPZQ7BdlD+xb7/AKDU/wD35j/+Jo/sW+/6DU//AH5j/wDiavxi/fy2leCLDNvRFL5X+HBOMH14NJHp4Cx/aLm4uHRWUs77QwbrlVwp9BxR7KHYLsy5rCa33eb4gkQqhkIMUWQo6nG3OKLGE2F5eXave6jcSQwrjyljBUMxG0naCfnJPPQevFbUFpb2yqsMKIFQINq9FHQfSpqapxi7pCuVHN+7usa28SrIu12Jcun8XAxtPYcn+lZieHriGe6kg1aeNbidpinlRkKT2GR7VvUVUoqSswMX+xb7/oNT/wDfmP8A+Jo/sW+/6DU//fmP/wCJraoqPZQ7DuzF/sW+/wCg1P8A9+Y//iaP7Fvv+g1P/wB+Y/8A4mtqij2UOwXZi/2Lff8AQan/AO/Mf/xNH9i33/Qan/78x/8AxNbVFHsodguzF/sW+/6DU/8A35j/APiaP7Fvv+g1P/35j/8Aia2qKPZQ7BdmD/wj10dRs7x9XmdrVyyq0KYYEYYHAB6E1qJ9vV1Dm3kUyNuKhkKp245yfXp+FWqKtRUVZCKa3dyvlCawk3OHLmF1dUx0ySQTntgfWhdTt9qmQSw7ojKfNiZQqjrk4wD7ZzVyjrTAijureZtsU8TttD4VwTtPQ/Q1LUE9la3SOk9vFKsi7HDoCGX0PtUb6bA3mFWmjMhUkxysv3emMHj+tAFuiqn2W5VyyX0hDTCQq6KQExygwBgd88mhP7QSSMObeVDI29gChVMfLgc5PryKALdVNR06DVLT7NceYE3q4MblGDKQwII56gU1Lu6CxedYSBmVmfynV1QjoMnBOe3FB1W1RQZTLD+5M58yJgFUdcnGAfbOaAKX/CNWv/P5qX/gbJ/jR/wjVr/z+al/4Gyf41qxXVvM22KeN22h8KwJwehx6Gpankj2C5i/8I1a/wDP5qX/AIGyf40f8I1a/wDP5qX/AIGyf41tUUckewXMX/hGrX/n81L/AMDZP8aP+Eatf+fzUv8AwNk/xraoo5I9guYv/CNWv/P5qX/gbJ/jR/wjVr/z+al/4Gyf41tUUckewXMX/hGrX/n81L/wNk/xrQ07T4NLsltbbf5Yd3y7lmLMxZiSeTksTVqimopbIAooopgYd94WsbqV5oGktJXOWMOMMfUqQRn3xmqY8IOTh9TkCj+5EoJ/E5H6V1FFYyw9KTu4o1jXqRVlIz9N0ay0sMbeMmVhhpXO52/H09hxWhRRWqSSsjNtt3YUjKrqVZQykYIIyCKWimI5m58Gwhy2mXktkCc+TtEkQ+inlfoCB7VCnhC8dgLjWcR9xbWwRj+LM38q6yirVWaVkyXCLd7FHTNHstHgaOzh2ljl5GJZ5D6sx5NXqKKgoKKKKACiiigAooooAKKKKACiioZLq3ilSKSeNZZAxRCw3MF64HU4oAmoqkdQ3qDb20826EyoduwHHRfmwQT9KHOoyo6xiC3LRAq7EyFX7grxkD1zQBdpjyxxbfMdU3EKNxxknoKryWTzeYJbufa5UhUbZtx1wRzg98k09bG1VnYQJueTzWJGSW9frQAxNStZHRYnaXe7Rho0LKGXqCwGB+NNjub2cRMtj5COrb/PkG9CPu/KuQQf94Yq6AB0GKKAKf2a7lTE14U3QlGECBRvP8QJyR7DNDaZaybvPRp96KjCViysFORweM55zirlFACBVGcKBnrxS0UUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUEA9RRRQBBPZ21zG8c8EciSAK6soIYDoDUT6bA7OymWJndXYxSsuSvToenqO9XKKAKv2a4VgUvZMedvIdVPy/wBwcdPfrTYxqKPGJWtpVLPvZVZCF/hwMnJ7Hp/SrlFAFKO7ugIhcae6uyMzmKRXRCOgycE57cflSjU7Yf6zzYcQeexliZVVfdsYB9s5q5QRnrQBDHdW8rlI54nZVDFVcEgHofxqaoLiytbqN47i3ilRwAyugIODkZ+hqN9OgZnZTLGXkWRjHKy5I47Hp6jvQBboqp9luFdSl9Lt84yMrqpyp/gHHA/WlT7ehjDm3kGW3lQU4/hwMn8aALVFUku7pUQz2DqxjZ38pw4UjovOCSe3FOOpW6IWl8yICITMZIyAq+5xjPtnNAFuioo7q3ld0jnjd02l1VgSueRkds9qloAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAKeq3zadp0lykQlcMiKhbaGZmCjJwcDJ9KzDN4od2zZWEaCUFQlySSncElOp9RirXiP8A5Ax/6+Lf/wBHJWrQBgJHrIYNLZRysspkXdqBAGe2BGAQPepLcajaRpHb6HYRImdqpdkAZ5OP3dbdFAGX9q1r/oFWv/gaf/jdH2rWv+gVa/8Agaf/AI3WpRQBl/ata/6BVr/4Gn/43R9q1r/oFWv/AIGn/wCN1qUUAZf2rWv+gVa/+Bp/+N0fata/6BVr/wCBp/8AjdTa0SNDvyCQRbycj/dNUJNN02KNpJIIURRlmbgAe5rGrWVO10NK5Z+1a1/0CrX/AMDT/wDG6PtWtf8AQKtf/A0//G6xTNpLH9xp0twv99IwB/48Rn8KBNo6ti4sJLYf3pUG38SpIH44rH65HaxXs2bX2rWv+gVa/wDgaf8A43R9q1r/AKBVr/4Gn/43VddL051DLbxMpGQRyCKX+ybD/n1j/Kn9bj2Fyk/2rWv+gVa/+Bp/+N0fata/6BVr/wCBp/8AjdQf2TYf8+sf5Uf2TYf8+sf5UfW49g5Sf7VrX/QKtf8AwNP/AMbo+1a1/wBAq1/8DT/8bqD+ybD/AJ9Y/wAqrpb6RJJcIIY1Nu4SQupUAkA8E9eo6UfW12DlL/2rWv8AoFWv/gaf/jdH2rWv+gVa/wDgaf8A43VA2umkEx2Rkx2WMj8icA0C10wAeZZ+VkZ+dDgfUjgfnR9bXYOUv/ata/6BVr/4Gn/43R9q1r/oFWv/AIGn/wCN1XXStPdQy28RU8gjoaX+ybD/AJ9Y/wAqPrcewcpP9q1r/oFWv/gaf/jdH2rWv+gVa/8Agaf/AI3VG6tdIsYfNuY4YkzgFu59AO59hWUdS0XP7vS7iRezCNQD+DMD+lJ4yK3RUaUpfCrnR/ata/6BVr/4Gn/43R9q1r/oFWv/AIGn/wCN1iWlzoN3KsXkCCZjhUmTbk+gPQn2BzWp/ZNh/wA+sf5U/rcewnBp2ZP9q1r/AKBVr/4Gn/43R9q1r/oFWv8A4Gn/AON1B/ZNh/z6x/lUL2elI+zyEZgcFUUsR9cdKPrcewuUu/ata/6BVr/4Gn/43R9q1r/oFWv/AIGn/wCN1ni0sMtu051VRncUzn6YJNSJY6VISFhi3DkqRgj8DzR9bXYOUufata/6BVr/AOBp/wDjdH2rWv8AoFWv/gaf/jdUrSz0u+tI7mC2UxSDK7kKn8QeRU39k2H/AD6x/lR9bj2DlJ/tWtf9Aq1/8DT/APG6PtWtf9Aq1/8AA0//ABuoP7JsP+fWP8qP7JsP+fWP8qPrcewcpP8Aata/6BVr/wCBp/8AjdH2rWv+gVa/+Bp/+N1B/ZNh/wA+sf5VVu4tGsmCSwp5jDKxopZj+A7e/Sj63HsHKaP2rWv+gVa/+Bp/+N0fata/6BVr/wCBp/8AjdYnmWGM/wBi3OP91P8A4qrNpHo145jihQSgZMTqVYfgeo9xxSWMi9kNwa3NL7VrX/QKtf8AwNP/AMbo+1a1/wBAq1/8DT/8bql9jt7TV9MaCIRlpnVtvceU5x+groa6KdRTjzIlqxl/ata/6BVr/wCBp/8AjdH2rWv+gVa/+Bp/+N1qUVoIy/tWtf8AQKtf/A0//G6PtWtf9Aq1/wDA0/8AxutSub8T+IJ9EvdPjjeKOG4SdpZHheUr5aBhgKR70AaH2rWv+gVa/wDgaf8A43R9q1r/AKBVr/4Gn/43VOLxVaxpHHdBzMC8LyRL+7eaNN8iLk57NjPoeakl8VWEUe/y7hhi2ICoCSLhtseOfUYPpQBY+1a1/wBAq1/8DT/8bo+1a1/0CrX/AMDT/wDG6pf8JXbQyy/a0lt+YUjhlQLJvkDHBO7HRT6YwetTWniizvrm3gtre7laaKObcIxhEdmUFuexUg9aAJ/tWtf9Aq1/8DT/APG6Q3WtHrpVp/4GH/43VNfEEltca39qieWKyuhHH5KgHaYEk5JIHViPyp8fi3TpfuLPgtEASoGVkjMgfr93aDk+xoAfMNSuUdJtDsZFfG4Ndkg45Gf3fao2g1IuzrpcMbPKJWMeoum5h64Tkeo6Go4/GulzJG0KXErSPEiIiqS3mKxT+LHO09eR3xW/bzfaLaKfy5I/MQPskGGXIzgjsaAMQHxCrqRBEQJS5VrsHKn+H/VdB+dEd14pVoxLpumSDLeYyXTpx/DgFD+Nb9FAFXTbz+0NMtbwx+WZ4lk2ZztyM4z3q1WZ4c/5FrTf+vdP5Vp0AFFFFABRRRQAUUUUAFFFFABRRRQBleI/+QMf+vi3/wDRyVq1leI/+QMf+vi3/wDRyVq0AFFFFABRRRQAUUUUAUda/wCQFqH/AF7yf+gmueZ/7Wn+0Sc2iN+4j7Nj+M+ue3tz3rX8VXEEHhnUlmuI4WltpI4y7AZYqcAeprPijSGJIo1CoihVA7AdK83MZW5UjooRTbbH0EAjB5FYXim71Cx04TWMuxiyxqFUM7SO6IgAbjHzNn6D3rR01blbYtdSyyMzFlEqKrIOODt49T+NeXy+7zHVfWxJbyHSrlApxZTOFZO0Tk8MPQE8Eepz653yMgisC/jE2n3EZON0bDI7cda2baRprOGU8M8asfYkV0UpNrU5qsUndFOSE2z4Nyzg87ZJ2VgPqO34fjUkaiRFYJc4YZ4nJH57qfFZvFkiclm5Zioyaja1uICZLebqctHtADfT0NbGQn2eeQDG+EHu0zMfyB/qagt7OzWe6eW6eSSKQBmec5QlF7Z4OD/Kp/tLElVknMn9zycc/XGP1qG006Rbq5uJZB5ryA8IMD5R+Z7ZoAupDDICUmlYA4OJm4/WnfZEP8c3/f1v8aikspGfzEuCko6MEHPsfUU1ZJ1BWd5Fcf3Y9wP0wKQCx6XBFeJcxvOpUNlBM2xie5XOCeKmvLqOxs5bmYnZEpY46n2HvVeGO9kvEme4KW6ggwlBlyehJ7Y9BVLxQxNhbRZ+WS5UN77Qzj9VFKTsrlQjzSUe5gSPNeXBu7s7pm+6uciIf3V/qe9OornPEmoSWt1bojTiOOGWebyX24A2qpb2y2f+AmuJJ1JHu2jTjpsdC8aSoUdQynqCK2fD2oy+adNuZGkIXfBIxyWUdVJ7kcc9x9M1g2STx2Nul1IJLhY1ErgcM2OT+dWrbK6pYODhlnAH0IKn9DVUpOMrGOJpqdNt7o7KaJZ4mjcsFPXaxU/mKiSxhjUKhlVR0AlYf1qaUSNEwiYK+OCRkZqmJ3AIkllRx1Xys/kQOa7Dxix9lQf8tJv+/rf41XNtY3Z2ecZCOcCckj360gt7m65mlZIu0ZUZb/e/wqWWyMybWlxjoQoBH0pgU7G1b7FDJbXTTxMuVBnYgj2YH/GrIjbndFcg5xxOSPr1qtYrNZWkUEjMiKMIUiGPxAHB/Sp/9KuflimeOI9ZGQAn6Aj9TQwGsjsxRXMRzjMlwxP5A/1qezsRaSSyfaLiVpcZ82QsBgY4HQULY7IzGHG09coDn60llaT2sk2+7aaFiPKjZQPLGORnqaAG6nePaQIsIBuJm8uIHoDjJJ9gAT+neqFvbJbgnJeVzmSV+Wc+pNSX37zXEz0htvl997c/+gD86dXLWk78p00oq1wqG4tkuFG7KupykinDIfUGucgudaufEN1afapVigWLc0UUZjVzlmUk/Njbs9T81bdv9s/tSYzBvJMEe3B+UPlt2O/TbUOLj1NL3LVneSXOoabFcY+0wXLrJgYDfuXww9iP1BHauprildY/GujrvAadZcr3bYjY/Lefzrta9vBu9JM4qitKwUUUV1GYVSutLgu9Ssr6Qv5tn5nlgHg7xg5/CrtFAGL/AMIvp5umlYSMhmkuBCW+VZJFKuw78gt37moIfCFnFEqNc3UmPs2GdwTi3ctGOnY9fXvXQ0UAY194btb67ku2lmjuGkilSRCP3bIGUEAjHR2BznOatW2kw22om+EkrzNbpbsWOQVVmYH65Y1fooAw7nwvaXN3Lcme4SSW4+0PtYYJ8oREdOm0D3HUVX0/wvHDqXnXEcZhgslsIAHLF4xkbn4A3YJHHq3PNdJRQBiQ+GbaK2srdrm5lSzmSWDewyuwEKvA5GCevJ9a26KKACiiigDM8Of8i1pv/Xun8q06zPDn/Itab/17p/KtOgAooooAKKKKACiiigAooooAKKKKAMrxH/yBj/18W/8A6OStWsrxH/yBj/18W/8A6OStWgAorJ1zWk0mFFRBLdS58qPPHHVj7CuMubm7v2LXtzJLn+AHag+ijj+taQpuWxlUrRhoz0mivL4oEgO633QN/eiYofzFdDo/iWeGdLXUpBJE5CpcEYKnsG9vf8/WnKjKKuTDERk7bHX0yWWOCF5pXVI0UszMcAAdSafWEf8Aiob0qOdKtn+Y9rmQHp/uKfzI9BzkbnE614GGuasfFrSTxQpDOBazSM26Mwuqvgn5TuIIA6DHeulspXeDy5j/AKRCfLmH+0O/0PUexrf1r/kBX/8A17Sf+gmqF9ppnlFzbSCG5AwSRlXHow/r1Fedj4c1jajPlZnzafbXF3Fcyx7pYvu5JxkdDjoSMnHpVmq7S3cJ2z6fNnu0RDr/ADB/ShXvZ/lgsJFJ/jnIVf0JP6V5ns57WOrnj3GX4M8QskP726/djHUKfvN+Az+OPWug+5H8q52jhRVOw04WjNPNJ5104w0mMAD+6o7D/Jq8TgE+ldEI8qsc9SfMyn9u/wBH8/yW8vGc7h+X19qiAu5V8x0lSQ8qFcYX2x3/ABqv58aOt5LEcMQWTyW+T0Occkd6tz6iilY4g5lfpmJsAdyeP85FaWMxYb2R42L25R04kG4fKf8ACqNmLq4ub2aRrkxPKDFH5gGwbF6Y9euKnWa3lmMd0jSSIAVfyWG5fcY9f6VBBfXD3l+VdfJSUCIC3fJ+Rchj9e/+HLAuw3VwrmCWFjIoyrZA3r6/X1pvnz3MxCxOsMZwSrAF29M+gpJb6yntBNKkhUDODE2QemOnXPFMivhbeWJVKxP8oVIWHlnsOnI7fX68ICWKS7jvkhNu7WzqSZGcExkdvUg/pio9fs3vNJkES7pomE0YHUlTkgfUZH41YGpWxvIrQeb5sqsy/umxgYzk4wOverdJ+Y02ndHCRyLLGsiHKsMg1FJZ200jyS28bu8ZiZmUElP7p9vat/UvD8hne505kVnOXgc4Vj6g/wAJ/SshoL+Ntr6bdA+wVgfyNccqUovQ9iniac1q7MaqqihVACgYAHYVZ0m3N5rUIAzHa/vZD23YIVf1J/D3ot9J1O8IHkfZEPV5iCw+igkfmfwNdPYWEGnWoggBxnLMxyznuSfWrpUmnzSMcTiY8vJDW5aoooroPMCiiigAooooAKKKKAMfWF8i6tb4/wCrUNDKf7oYghj7AjH/AALNBAIIPQ1rSRpLG0cihkYYZSMgisV7C8sOLcfarYdELYkQegJ4YfXH1rKpTctUb06iWjI7Kwt9PiaO2TaGO5iSSWOAMknk8AD6AVZqt9pm6f2feb/7u1f55x+tSJY3t9xMDaW5+8obMrD0yOF/DJ9xWSpzb1NHUikZkmnLrOsWc5do1SdoraZOGV1jkJcf8CCj/gJ7Gur0rUJLnzLS8UR39vgSoOjDs6/7J/Q5HaqjxRwaho8USBI0mZVVRgAeS9W9V0+S48u7s2WPULfJhZujg9Ub/ZP6HB7V7eEVqdjjm7yuaVFVNN1CPUrQTIrRupKSxP8AeicdVPv/AD4PQ1W17XLfQbD7RKC8rnbDEDgu39B6n/61dDaSuyYxcnyrc1KK8d1HXtU1WQtdXbqh6QxEqg/Dv+Oazoi1u++B3if+9GxU/mK4pY+Cdkj1oZPVcbtpM9zorznw/wCNrm0mS21aXzrVjgXDfej/AN71Hv1FejAgjIOQa6qVWNRXiedXw9ShLlmgooorQxCiivPPEPjaeeeS00iTy7dDta5HLSHvt9B79+3vnUqxpx5pG1ChOvLlgj0OivDZme5ffcSPM/8AekYsfzNXtP1zU9KkDWt3JtHWKQlkP4Hp+GK5Vj4N2aPRlk9VRummz2Sisjw/r8Gv2RlRfLnjIWaEnJQ+o9QexrXrtTTV0eVKLi3GW6Mzw5/yLWm/9e6fyrTrM8Of8i1pv/Xun8q06ZIUUUUAFFFFABRRRQAUUUUAFFFFAGV4j/5Ax/6+Lf8A9HJWrWV4j/5Ax/6+Lf8A9HJWrQB51qNw15rN7cMc4lMKeyoSv89x/Gs6TUrOKFpWuEKgMeDnO07Tj8SB9au3MRt9RvoGGGS4c/gx3D9GFYbaGFVvnL7rwXGMYCjzA5A/EZ98V3R0irHmT1m+YvrfwsGXenngHMW4bgQM4/Ij86lVo7q2Vh80UqAjPcEVlS6VdGS8dZ08y9iWJ2VMeWRkFhz/AHT09RWvFGkEKRIMIihVHoBVK/Uh26HQ6ZqNxr+mwaZBK4aMGO/uVOCoUldoP99gM57A56kV1UEEVtBHBDGscUahURRgADoK5nw5oUEuixXMj3Mbzs8v7qd48qzEqcA9cEVpjRJIQPsurahEfV5fO/8ARm6uB76Hqx2Vy7qUD3Wl3dvFjzJYXRdxwMkECqGdX/6B9t/4FH/4il367ZcultqEQ/uZhkA/HKsf++amttcsriUQSM9rck48i5XYxPt2b8CaynSjP4ik7EGdX/6B9t/4FH/4ijOr/wDQPtv/AAKP/wARWzRUfVqfYOZmNnV/+gfbf+BR/wDiKM6v/wBA+2/8Cj/8RWzRR9Wp9g5mYrrqzoyNp1qVYYI+1Hkf98VFDBq0TFjZQO2AoLXZ4Hp9yt+ij6tT7BzMwZoNWm2n7DAjr911uyCPX+CiCDVLdWWPT7cBjuObsnnAH9z2reoo+r0+wczOeNpqhm8z7DBtzuKfaztLeuNlTSJqssbRvp1sVYYP+lH/AOIrboo+r0+wczMCGDVYct9hgd26u12ST/45U2dX/wCgfbf+BR/+IrZoo+rU+wczMbOr/wDQPtv/AAKP/wARRnV/+gfbf+BR/wDiK2aKPq1PsHMzGzq//QPtv/Ao/wDxFGdX/wCgfbf+BR/+IrZoo+rU+wczMbOr/wDQPtv/AAKP/wARRnV/+gfbf+BR/wDiK2aKPq1PsHMzGzq//QPtv/Ao/wDxFGdX/wCgfbf+BR/+IrZoo+rU+wczMbOr/wDQPtv/AAKP/wARRnV/+gfbf+BR/wDiK2aKPq1PsHMzGzq//QPtv/Ao/wDxFGdX/wCgfbf+BR/+IrZqhda1p9nJ5UlwGm/54xAyP/3yuTR9Wp9g5mVc6v8A9A+2/wDAo/8AxFGdX/6B9t/4FH/4inf2lql0P9D0kxqej3koT8Qq5J+hIo+x61N/rtVigH/TrbAf+hlqPq1PsHMxudX/AOgfbf8AgUf/AIijOr/9A+2/8Cj/APEU8aPcM26bWb+Q+zKg/wDHQKR/D0Mhy9/qmf8AZvpVH5A0fVqfYOZjEttSn1GylntoIooHZ2Kzlycoy4xtH96tqsoeH7UDBudQP1vZT/7NSHw7ZHrLen/t7k/xrWEFBWQm7nLeOPEM3hyS5vNBs5r3VFi23NtCoYbSDsdhnPB6EA5GR9OZ1fXD4huoLzcWjW2iVB6FkVn47HJwf90V10nw1sbnxkviC4vb3MMaxwQpcOMYySWbOTyTx0rl/E1n9h8T38QXajuJk46qyj+oYfhXLjm/ZaHp5UovEa9mZLyJEheR1RR1ZjgCqtvqVtcTSxrPCWWTYoEgJbgH+v6VbIDDBAI9DUEFpHDJM4VcyPvHHTgD+leQrW1PpJc11YsEZGDXp/ge+e88NRxyNue1drck+gwV/wDHWUV5hXc+CvD8Fxokl5O1ypubhnUJO6DAATOAf9g124Bv2jXkeXnCj7GLe9zuqKyP+Ecsf+el5/4Fyf40f8I5Y/8APS8/8C5P8a9Y+cM7xPr1u3hO4m0+6SQzuLYPG3KknDA+hChvoa8zAAAAGAOgrdv/AIb2vhzSb/WEurm4vpLr7RNmQ+WFZiCAuewbOTk8GsOvKzBvnS6WPosmUfZSfW5QvNZsrGUxTSNvVQzBELbQehOBxVuCZbiFZUDBW6blKn8jWXcafcrcai8CRSJexhT5jY2MF2+nIxj/ACa0rSBrayggZzI0UaoXPViBjNcclFLQ9OEpuT5tjoPCV69j4ntCDiO4JglHqCPl/wDHgPzNes14/wCHLdrrxNp0SjOJhKx9AnzZ/MAfjXsFergW/Za9z53NlFYjTtqZnhz/AJFrTf8Ar3T+VadZnhz/AJFrTf8Ar3T+Vaddh5gUUUUAFFFFABRRRQAUUUUAFFFFAGV4j/5Ax/6+Lf8A9HJWrWV4j/5Ax/6+Lf8A9HJWrQBzniTRJbpxqFkm64VdskeceYo6Y/2hzj61yaSK7MoyHX7yMMMv1B5Fen1TvNJ0/UCDd2kMrDoWQEj8a1p1XHQwq0FN3W558SFUsxAAGST2q3pekza3KFCsliD+9mPG8f3V9c+tdZD4a0eFw62ELMDkFxuI+ma1QoUAKAAOwqp121ZEQwyTvJgiLGioihVUYAHQCloorA6gqG5tLe8iMVzBHKh6q65FTUUAY/8AZF1Zc6VfPGo6W9xmSP6DPI/A0f21NaHbqljLAP8AnvDmWP8AQZH4jHvWxQRkYPSgCK3uYLuETW00c0Z6PGwYfmKlrMuNCsppmuIQ9rcnrNbsUY/XHDD2PFRf8Tyxx/qdSiHc/upcfh8pP4CgDYorKTxDZKwS7EtjJ/duU2j/AL65X9a045Y5kDxOroejKcg0AOooooAKKKKACiis7Xb9tN0iaePHnHEcWf77HAP4Zz+FJtJXY0m3ZFPVvEkdjM1raxi4uV+/zhI/qfX2H6VhtrusSNuN4kfP3Y4lx/49k1nRxiNNuST1LE5LHuT71C2oWitKrToDFIsT54w7Y2j6nI/OvDq42rOXuaI9mng6cF72rN+18UX9uw+2RJcxd2jG1x+HQ/pXVWl3BfWyXFtIJIn6EfqD6H2rzqG4inMgicMY3KPjsw7VreHbxrLWVt8/uLzIK9hIBkH8QCD9BXRhMZOU/Z1OphisJFR56Z21FFFeqeYFFZ91rdjaymHzTNcf88IBvf8AEDp+OKr79a1D7iR6bCf4nxJN+X3VP/fVAGlc3VvZwma5njhjBxukYKM+nNZv9sz3h26XYSTD/nvPmKP8Mjcfy/GpbbQrOCYXEoe6uR/y2uG3sPpn7o9hgVp4wMCgDH/si7vOdT1CR1P/ACwtsxR/p8x/E1oWlhaWMYjtbeOFfRFAqxRQAUUUUAFFFFABRRRQAVzXi7w22tWyXFrtF9ACFzwJF7qf6H/GuloqZRUlyvYunUlTkpx3R4bIjwzNBNG0Uy/ejcYYfh/Wkr2i90uw1JQt7ZwzgdPMQHFZ8XhHQYX3rpluT23Lux9M150sv10loe3DOVy+9HU860PQbrX7hVhDR2mf3lxjjHovqf5V63bW8VpaxW0CBIokCIo7ADAp6IsaBUUKo6ADAp1dtGhGkrI8vFYueJleWy6BRRRWxyjJoY7iCSCZA8UilHU9CDwRXkuveHrnQLhtyvJYk/u7jrgej+hHr3r12kZVdSrKGU9QRmsa1GNWNmdOFxU8PLmj9x4aDkZHSlRWklWGJGklf7saDLH8K9Ym8JaDO+9tMtwxOSVXbn64q9Y6Tp+mgiys4IM9fLQDNcSy/XWWh6ss5XL7sNTD8H+Gn0eJ7y8A+2zrt2jnyk67fqep+g9K6iiivRhBQjyx2PEqVJVJOct2Znhz/kWtN/690/lWnWZ4c/5FrTf+vdP5Vp1RAUUUUAFFFFABRRRQAUUUUAFFFFAGV4j/AOQMf+vi3/8ARyVq1leI/wDkDH/r4t//AEclatABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFADXjSRdrorD0IzWbJ4d01pDJHAbeQnJe3cxn81rUooAyRo9zGAINZvkA6Bysn/AKECaP7P1VemtOx/2reP+gFa1FAGQLXXlP8AyErRh/tWx/o1P8nXP+fyxP8A27t/8VWpRQBy3iW18RzeG9Qjtri2a4aEiEQRMr+Z/Dg7+Occ1kfZfEtr4TsR4nvLe6u0uULNDHjaCrKNx7ncRzgV6BVXUrFNS06e0c7RIvDDqrDkH8CAfwqKkeeDj3RdOXLNS7HBVyOqaXqU97qUkMG5BdQXFuu4DzHAjUk+gARvzrrSssMz21ynl3MfDr6+49QaWvnE5UpNNan0DUakU09CvZWos7VYgdzcs7/3mJyT+Jq1biVtRskgKiZpxsLDIBAJyQPYGmEhQSSABySa2/C+nPPdf2pKpESKVtwR94nq/wBMcD6mtcJTlUrJ9tTHFTjCk130Nc2utyEBtSto17mK35/8eJFIdC8//j+1C8uh3Qv5an6quAfxrXor6E8Ir2tja2MYjtbeOJR2RcVYoooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAzPDn/Itab/17p/KtOszw5/yLWm/9e6fyrToAKKKKACiiigD/2Q==)\n",
        "\n",
        "_* borrowed from Li et. al. and modified for purposes of notational consistency_"
      ],
      "metadata": {
        "id": "1G0W229Sgo9y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given $\\mathcal{X} ⊂ \\mathbb{R}^{d_x}$, $\\mathcal{Y} ⊂ \\mathbb{R}^{d_y}$ we refer to $x \\in \\mathcal{X}$ as the input and  $y \\in \\mathcal{Y}$ as the query locations. We define functions $u^l \\in \\mathcal{C}(\\mathcal{X}, \\mathbb{R}^{d_u})$ the input functions and $s^l \\in \\mathcal{C}(\\mathcal{Y}, \\mathbb{R}^{d_s})$ the output functions. \n",
        "\n",
        "Our goal is to learn an operator $\\mathcal{G}: \\mathcal{C}(\\mathcal{X}, \\mathbb{R}^{d_u}) \\to \\mathcal{C}(\\mathcal{Y}, \\mathbb{R}^{d_s})$ using pairs of input/output functions $\\{ u^l(x), s^l(y) \\}_{l=1}^N$. To do that, we will consider the Fourier variant of the Neural Operator architecture. \n",
        "\n",
        "\n",
        "The Neural Operator is an iterative architecture defined as $v_0 \\mapsto v_1 ↦ ... \\mapsto  v_T$ for $v_j$ where $j=1,...,T-1$ transforms in $\\mathbb{R}^{d_v}$ and is constructed in three parts:\n",
        "\n",
        "1.   Applying $v_0$ to the input function lifts it to a higher dimensional representation $v_0(x) = P(u(x))$ where $P$ a local transformation, i.e. a shallow MLP. \n",
        "2.  Iteratively apply updates $v_t ↦ v_{t+1}$ for $v_j$ where $j =1, ..., T-1$.\n",
        "3.  The last transformation $s(x) = Q(v_T(x))$ projects the representation back to the dimensions of the output function, using again a local transformation. \n",
        "\n",
        "**Let's examine how Step 2. works:**\n",
        "\n",
        "The function in Step 2 is defined as:\n",
        "\n",
        "$$v_{t+1} = \\sigma( W v_t(x) + (\\mathcal{K}(u;\\phi)v_t)(x)), ∀ x \\in \\mathcal{X}.$$\n",
        "\n",
        "We can choose $\\mathcal{K}(u;\\phi)$ to be an integral operator and get:\n",
        "\n",
        "$$v_{t+1} = \\sigma (W v_t(x) + \\int_{\\mathcal{X}} \\kappa (x, y, u(x), u(y); \\phi)v_t(x) dy, \\quad ∀ x \\in \\mathcal{X},$$\n",
        "\n",
        "where $\\kappa_{\\phi}$, a learnable kernel represented by a neural network parameterized by parameters $\\phi$, $W$ a linear transformation and $\\sigma$ a non-linear element-wise activation function. \n",
        "\n",
        "\n",
        "In the Fourier Neural Operator architecture, the kernel is considered to be stationary and independent of $u$, thus it can be replaced by a convolution operator defined in the Fourier space:\n",
        "\n",
        "$$(\\mathcal{K}(\\phi)v_t)(x) = \\mathcal{F}^{-1} (\\mathcal{F}(\\kappa_{\\phi}) \\cdot \\mathcal{F}(v_t))(x)$$\n",
        "\n",
        "where we can parameterize the Fourier transform of the periodic function $\\kappa$ by $R_{\\phi}$:\n",
        "\n",
        "$$(\\mathcal{K}(\\phi)v_t)(x) = \\mathcal{F}^{-1} (R_{\\phi} \\cdot \\mathcal{F}(v_t))(x).$$\n",
        "\n",
        "**Truncating the modes of the transform and assuming the domain $\\mathcal{X}$ is discretized using a uniform grid we can consider the FFT and Inverse FFT of $\\kappa_{\\phi} v_t$, which can be represented as matrix-vector multiplications between the corners of $R$ matrix and $\\mathcal{F}v_t$.**\n",
        "\n",
        "**For more information on why this is true please refer to the Fourier Neural Operator paper by Li _et. al._ Sections 3 and 4:**\n",
        "\n",
        "- [FOURIER NEURAL OPERATOR FOR PARAMETRIC PARTIAL DIFFERENTIAL EQUATIONS](https://arxiv.org/pdf/2010.08895.pdf)\n",
        "\n"
      ],
      "metadata": {
        "id": "ZENTc_LCnxI-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting flow through a porous medium\n",
        "\n",
        "Fluid flow through porous media is governed by Darcy's Law, which can be mathematically expressed by the following partial differential equation system,\n",
        "$$ \\nabla \\cdot ( u(x) \\nabla s(x)) = f(x), \\quad x \\in \\mathcal{X},$$\n",
        "subject to appropriate boundary conditions\n",
        "\n",
        "$$ s = 0   \\quad \\text{on} \\quad \\Gamma_\\mathcal{X},$$ \n",
        "$$(u(x)  \\nabla  s(x)) \\cdot n = g  \\quad \\text{ on } \\Gamma_N, $$\n",
        "where $u$ is permeability of the porous medium, and $s$ is the corresponding fluid pressure. Here we consider a domain $\\mathcal{X} = [0,1] \\times [0,1]$ with a Dirichlet boundary  $\\Gamma_D = \\{ (0,x) \\cup (1,x)\\;|\\;x_2 \\in [0,1] \\subset \\partial \\mathcal{X} \\}$, and a Neumann boundary $\\Gamma_N = \\{ (x,0) \\cup (x,1) \\;|\\;x \\in [0,1]\\subset \\partial \\mathcal{X} \\}$. \n",
        "\n",
        "For a given forcing term $f$ and set of boundary conditions, the solution operator $\\mathcal{G}$ of system maps the permeability function $u(x)$ to the fluid pressure function $s(x)$. In the notation of our model, the input and output function domains coincide, $\\mathcal{X} = \\mathcal{X}$ with $d_x = d_y = 2$. Since in this case the solution operator is a map between scalar functions, we also have $d_u = d_s = 1$. Under this setup, our goal is to learn the solution operator $\\mathcal{G}: C(\\mathcal{X}, \\mathbb{R}) \\to C(\\mathcal{X}, \\mathbb{R})$. \n",
        "\n",
        "We set the Neumann boundary condition to be $g(x) = \\sin(5x)$, the forcing term $f(x) = 5 \\exp( - ((x_1-0.5)^2 + (x_2-0.5)^2))$, and sample the permeability function $u(x)$ from a Gaussian measure, as $u(x) = \\exp(u_0 \\cos(x))$ with $u_0 \\sim \\mathcal{N}(0, 7^{3/2}(- \\Delta + 49 I)^{-1.5}$. The training and testing data sets are constructed by sampling the initial condition along a $N_x \\times N_y$ grid and solving the forward problem with the Finite Element library, Fenics. This gives us access to $N_x \\times N_y$ solution values to use for training different operator learning models."
      ],
      "metadata": {
        "id": "G2yCqJoMWZ5t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## An even more in depth introduction to Stax"
      ],
      "metadata": {
        "id": "i2bqnFrphnQT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing the libraries necessary to implement FNO"
      ],
      "metadata": {
        "id": "OcOmREsahsYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax.numpy as jnp\n",
        "from jax import random, grad, jit, vjp\n",
        "from jax.example_libraries.optimizers import optimizer, make_schedule, exponential_decay\n",
        "from jax.example_libraries.stax import Dense, Gelu, serial\n",
        "from jax.nn.initializers import glorot_uniform, normal, glorot_normal\n",
        "from jax.ops import index, index_update\n",
        "from jax.flatten_util import ravel_pytree\n",
        "\n",
        "import numpy as np\n",
        "from functools import partial \n",
        "from torch.utils import data\n",
        "from tqdm import trange\n",
        "import itertools\n",
        "import timeit"
      ],
      "metadata": {
        "id": "JyPHht39gnns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fK5z5RKZZCoY",
        "outputId": "6e342022-586a-44b9-940e-d1013a746b1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adam optimizer for complex parameters\n",
        "\n",
        "As explained above the Fourier Neural Operator architecture consists of complex variables, which means that we need to change some parts of the Adam optimizer in order to properly use it.\n",
        "\n",
        "In short, the gradient based optimization can be written as:\n",
        "\n",
        "$$ \\mathbf{\\phi}_{i+1} = \\mathbf{\\phi}_i - \\lambda \\nabla \\mathcal{L}(\\mathbf{\\phi_i}), $$\n",
        "\n",
        "where $\\phi$ the network parameters and $\\mathcal{L}$ the loss function. In the case of complex network parameters JAX will return the derivative of the loss function with respect to a complex parameter as the Wirtinger derivative (https://en.wikipedia.org/wiki/Wirtinger_derivatives):\n",
        "\n",
        "$$\\frac{\\partial \\mathcal{L}}{\\partial \\phi} = \\frac{1}{2} ( \\frac{\\partial \\mathcal{L}}{\\partial \\phi_R} - i\\frac{\\partial \\mathcal{L}}{\\partial \\phi_I} ).$$\n",
        "\n",
        "where $\\phi_R$ the real and $\\phi_I$ the imaginary parts of the parameters. To perform gradient descent we need instead to use the other Wirtinger derivative:\n",
        "\n",
        "$$\\frac{\\partial \\mathcal{L}}{\\partial \\bar{\\phi}} = \\frac{1}{2} ( \\frac{\\partial \\mathcal{L}}{\\partial \\phi_R} + i\\frac{\\partial \\mathcal{L}}{\\partial \\phi_I} ).$$\n",
        "\n",
        "Therefore, we need to manually conjugate the derivative that JAX returns to us in the Adam optimizer.  Thet Adam optoimzer also computes the squared norm of a gradient by squaring its elements.  For a complex values this will not give us the squared norm, so we must change this expression to $\\bar z * z$.\n",
        "\n",
        "See that we are using the `optimizer` decorator for defining our Adam function, This decorator makes an optimizer defined for arrays generalize to containers.  With this decorator, you can write init, update, and get_params functions that each operate only on single arrays, and convert them to corresponding  functions that operate on pytrees of parameters (the default data structure that JAX uses to store network parameters). \n",
        "\n",
        "References:\n",
        "\n",
        "- [Optimizers Source Code](https://github.com/google/jax/blob/main/jax/example_libraries/optimizers.py)"
      ],
      "metadata": {
        "id": "kL9Ck7gyh3EC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqM_Bimns8h2"
      },
      "outputs": [],
      "source": [
        "@optimizer\n",
        "def complex_adam(step_size, b1=0.9, b2=0.999, eps=1e-8):\n",
        "  \"\"\"Construct optimizer triple for complex-valued Adam.\n",
        "\n",
        "  Args:\n",
        "    step_size: positive scalar, or a callable representing a step size schedule\n",
        "      that maps the iteration index to positive scalar.\n",
        "    b1: optional, a positive scalar value for beta_1, the exponential decay rate\n",
        "      for the first moment estimates (default 0.9).\n",
        "    b2: optional, a positive scalar value for beta_2, the exponential decay rate\n",
        "      for the second moment estimates (default 0.999).\n",
        "    eps: optional, a positive scalar value for epsilon, a small constant for\n",
        "      numerical stability (default 1e-8).\n",
        "\n",
        "  Returns:\n",
        "    An (init_fun, update_fun, get_params) triple.\n",
        "  \"\"\"\n",
        "  step_size = make_schedule(step_size)\n",
        "  def init(x0):\n",
        "    m0 = jnp.zeros_like(x0)\n",
        "    v0 = jnp.zeros_like(x0)\n",
        "    return x0, m0, v0\n",
        "  def update(i, g, state):\n",
        "    x, m, v = state\n",
        "    g = jnp.conj(g) # <- conjugate\n",
        "    m = (1 - b1) * g + b1 * m  # First  moment estimate.\n",
        "    v = (1 - b2) * jnp.real(jnp.conj(g)* g) + b2 * v  # Second moment estimate.\n",
        "    mhat = m / (1 - b1 ** (i + 1))  # Bias correction.\n",
        "    vhat = v / (1 - b2 ** (i + 1))\n",
        "    x = x - step_size(i) * mhat / (jnp.sqrt(vhat) + eps)\n",
        "    return x, m, v\n",
        "  def get_params(state):\n",
        "    x, m, v = state\n",
        "    return x\n",
        "  return init, update, get_params"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handling batches\n",
        "\n",
        "We are using the same data handler for sampling mini-batches as we did in the previous example. "
      ],
      "metadata": {
        "id": "PCbkCFKumGOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataGenerator(data.Dataset):\n",
        "    def __init__(self, inputs, targets, \n",
        "                 batch_size=128, \n",
        "                 rng_key=random.PRNGKey(1234)):\n",
        "        'Initialization'\n",
        "        self.inputs = inputs\n",
        "        self.targets = targets\n",
        "        self.N = targets.shape[0]\n",
        "        self.batch_size = batch_size\n",
        "        self.key = rng_key\n",
        "\n",
        "    @partial(jit, static_argnums=(0,))\n",
        "    def __data_generation(self, key, inputs, targets):\n",
        "        'Generates data containing batch_size samples'\n",
        "        idx = random.choice(key, self.N, (self.batch_size,), replace=False)\n",
        "        inputs = inputs[idx,...]\n",
        "        targets = targets[idx,...]\n",
        "        return inputs, targets\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        self.key, subkey = random.split(self.key)\n",
        "        inputs, targets = self.__data_generation(self.key, self.inputs, self.targets)\n",
        "        return inputs, targets"
      ],
      "metadata": {
        "id": "YltdqW_oiDri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the model and a more in-depth introduction to stax \n",
        "\n",
        "\n",
        "At this point, we need to make a more in-depth talk about how the `stax` library and especially the `stax.serial` function works. \n",
        "\n",
        "Essentially, `stax.serial` allows us to build complicated layers of function transformation by serially stacking layers that are defined as pure function in the stax syntax. \n",
        "\n",
        "That means that we define functions that are our layers that consist of an `inint` and an `apply` functions, where the `init` return the parameters of the layers and the shape of the output of the layer and the apply function is used to apply the transformation. \n",
        "\n",
        "By correctly defining the output shapes of each layer, the `stax.serial` function puts together the different layers by considering the input shape of the next layer as the output shape of the previous. In this way, we only need to provide the shape of the first layer and the whole transformation will work in a straight-forward manner. \n",
        "\n",
        "See an example:\n",
        "\n",
        "```\n",
        "input_shape = (-1, h, h, 3)\n",
        "layers = [Dense(width), \n",
        "          Permute(\"ijkl->iljk\"), \n",
        "          FNOBlock2D(h, modes), Gelu,\n",
        "          FNOBlock2D(h, modes), Gelu,\n",
        "          FNOBlock2D(h, modes),\n",
        "          Permute(\"ijkl->iklj\"),\n",
        "          Dense(128), \n",
        "          Gelu,\n",
        "          Dense(1)]\n",
        "```\n",
        "\n",
        "We vectorize again with respect to the batch dimension, which is why we provide and input shape to the first layer that contains -1 in its first dimension. This way `stax` will automatically apply a vectorization, to the `apply` function making it much faster.\n",
        "\n",
        "Reference:\n",
        "\n",
        "- [Stax Source Code](https://github.com/google/jax/blob/main/jax/example_libraries/stax.py)\n",
        "\n"
      ],
      "metadata": {
        "id": "zfgd0JRcmLdl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A simple Dense layer\n",
        "\n",
        "This is a dense layer construction, in terms of a pure function. You see that it returns an initialization function that provides us with the parameters of the neural network as well as the output shape of transformation which will be used as an input to the next layer. "
      ],
      "metadata": {
        "id": "2u1y572cms_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Dense(out_dim, W_init=glorot_normal(), b_init=normal()):\n",
        "    \"\"\"Layer constructor function for a dense (fully-connected) layer.\"\"\"\n",
        "    def init_fun(rng, input_shape):\n",
        "        output_shape = input_shape[:-1] + (out_dim,)\n",
        "        k1, k2 = random.split(rng)\n",
        "        W, b = W_init(k1, (input_shape[-1], out_dim)), b_init(k2, (out_dim,))\n",
        "        return output_shape, (W, b)\n",
        "    def apply_fun(params, inputs, **kwargs):\n",
        "        W, b = params\n",
        "        return jnp.dot(inputs, W) + b\n",
        "    return init_fun, apply_fun"
      ],
      "metadata": {
        "id": "1LoHI4usmwZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A Permutation layer \n",
        "\n",
        "This layer is used to permute its input in a user-defined manner. The permutation is necessary to correctly apply the Fast Fourier Transform to the inputs of the Spectral Convolution layer. "
      ],
      "metadata": {
        "id": "SkqJVqCMm2L6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Permute(order):\n",
        "    \"\"\"Layer constructor function for a permutation layer.\"\"\"\n",
        "    def permutation_indices(order):\n",
        "        if order==\"ijkl->iljk\":\n",
        "            return (0,3,1,2)\n",
        "        elif order==\"ijkl->iklj\":\n",
        "            return (0,2,3,1)\n",
        "        else:\n",
        "              raise NotImplementedError\n",
        "    def init_fun(rng, input_shape):\n",
        "        idx = permutation_indices(order)\n",
        "        output_shape = tuple([input_shape[i] for i in idx])\n",
        "        return output_shape, ()\n",
        "    def apply_fun(params, inputs, **kwargs):\n",
        "        outputs = jnp.einsum(order, inputs)\n",
        "        return outputs\n",
        "    return init_fun, apply_fun"
      ],
      "metadata": {
        "id": "ILmkq6CriMKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the convolution in the Fourier space\n",
        "\n",
        "This layer applies the transform\n",
        "\n",
        "$$\\mathcal{F}^{-1}(R \\cdot \\mathcal{F}v_t)(x).$$\n",
        "\n",
        "In a fast vectorized manner by considering the discrete case of the Fourier Transform and truncated modes. \n",
        "\n",
        "References:\n",
        "- [Convolutions in JAX](https://jax.readthedocs.io/en/latest/notebooks/convolutions.html)"
      ],
      "metadata": {
        "id": "ywORG8Bzmywz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def SpectralConv2d(modes, W_init=glorot_uniform(dtype=jnp.complex64), b_init=None):\n",
        "    \"\"\"Layer constructor function for a SpectralConv2d layer.\"\"\"\n",
        "    def compl_mul2d(input, weights):\n",
        "        # (batch, in_channel, x,y ), (in_channel, out_channel, x,y) -> (batch, out_channel, x,y)\n",
        "        return jnp.einsum(\"bixy,ioxy->boxy\", input, weights)\n",
        "    def init_fun(rng, input_shape):\n",
        "        k1, k2 = random.split(rng)\n",
        "        output_shape = input_shape\n",
        "        width = input_shape[1]\n",
        "        W1 = W_init(k1, (width, width, modes, modes))\n",
        "        W2 = W_init(k2, (width, width, modes, modes))\n",
        "        return output_shape, (W1, W2)\n",
        "    def apply_fun(params, inputs, **kwargs):\n",
        "        W1, W2 = params\n",
        "        batchsize = inputs.shape[0]\n",
        "        _, out_channels, modes1, modes2 = W1.shape\n",
        "        #Compute Fourier coeffcients up to factor of e^(- something constant)\n",
        "        x_ft = jnp.fft.rfft2(inputs)\n",
        "        # Multiply relevant Fourier modes\n",
        "        out_ft = jnp.zeros((batchsize, out_channels,  inputs.shape[-2], inputs.shape[-1]//2 + 1), dtype=jnp.complex64)\n",
        "        out_ft = index_update(out_ft, index[:,:,:modes1 , :modes2],  compl_mul2d(x_ft[:, :, :modes1 , :modes2], W1))\n",
        "        out_ft = index_update(out_ft, index[:,:,-modes1:, :modes2],  compl_mul2d(x_ft[:, :, -modes1:, :modes2], W2))\n",
        "        #Return to physical space\n",
        "        out_ft = jnp.fft.irfft2(out_ft, s=(inputs.shape[-2], inputs.shape[-1]))\n",
        "        return out_ft\n",
        "    return init_fun, apply_fun"
      ],
      "metadata": {
        "id": "WJMeqkXSm1O6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The FNO block\n",
        "\n",
        "This layer applies the transform:\n",
        "\n",
        "$$Wv_t(x) + \\mathcal{F}^{-1}(R \\cdot \\mathcal{F}v_t)(x).$$\n",
        "\n",
        "by considering an MLP and the Spectral Convolution defined above."
      ],
      "metadata": {
        "id": "lMXz3npVm8pC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def FNOBlock2D(out_channels, modes):\n",
        "    \"\"\"Layer constructor function for a 2D FNO block.\"\"\"\n",
        "    conv_init, conv_apply = SpectralConv2d(modes)\n",
        "    dense_init, dense_apply = Dense(out_channels)\n",
        "    def init_fun(rng, input_shape):\n",
        "        k1, k2 = random.split(rng)\n",
        "        _, conv_params = conv_init(k1, input_shape)\n",
        "        output_shape, dense_params = dense_init(k2, input_shape)\n",
        "        return output_shape, (conv_params, dense_params)\n",
        "    def apply_fun(params, inputs, **kwargs):\n",
        "        conv_params, dense_params = params\n",
        "        x1 = conv_apply(conv_params, inputs)\n",
        "        x2 = dense_apply(dense_params, inputs)\n",
        "        outputs = x1 + x2\n",
        "        return outputs\n",
        "    return init_fun, apply_fun"
      ],
      "metadata": {
        "id": "OJBExH-0m8ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss Function"
      ],
      "metadata": {
        "id": "9nLInB6gD6h1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For training the model, we consider a relative $\\mathcal{L}_2$ error loss: \n",
        "$$ \\mathcal{L}(\\theta) = \\frac{1}{N} \\sum_{i=1}^N \\sum_{j=1}^P \\frac{\\| s^i(y_j^i) - \\mathcal{G}(u^i)(y_j^i) \\|^2_2}{\\| s^i(y_j^i) \\|^2_2}$$\n",
        "\n",
        "as in the Fourier Neural Operators, which we will see in the next tutorial. The $\\mathcal{L}_2$ loss function weights each component differently depending on the norm of the target function sample. \n",
        "\n",
        "\n",
        "One of the reason we employ this loss function is to to avoid biasing the model towards over-fitting to functions with larger magnitudes. Moreover, there has been a success of methods that consider adaptive weights to the loss function and this is a intuitive way to choose the weights."
      ],
      "metadata": {
        "id": "svzpXw__mREB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LpLoss(object):\n",
        "    def __init__(self, d=2, p=2):\n",
        "        super(LpLoss, self).__init__()\n",
        "        self.d = d\n",
        "        self.p = p\n",
        "\n",
        "    def rel(self, x, y):\n",
        "        num_examples = x.shape[0]\n",
        "        diff_norms = jnp.linalg.norm(y.reshape(num_examples,-1) - x.reshape(num_examples,-1), self.p, 1)\n",
        "        y_norms = jnp.linalg.norm(y.reshape(num_examples,-1), self.p, 1)\n",
        "        return jnp.mean(diff_norms/y_norms)\n",
        "\n",
        "    def __call__(self, x, y):\n",
        "        return self.rel(x, y)"
      ],
      "metadata": {
        "id": "8WBM00uiiSqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Model Class\n",
        "\n",
        "We provide the model class in the same coding style as we did with the DeepONets. "
      ],
      "metadata": {
        "id": "JCHQZkIu_y_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FNO:\n",
        "    def __init__(self, input_shape, layers):\n",
        "        # Apply and init functions\n",
        "        self.init, self.apply = serial(*layers)\n",
        "        _, params = self.init(random.PRNGKey(10000), input_shape)\n",
        "        _, self.unravel = ravel_pytree(params)\n",
        "\n",
        "        # Relative L2 loss\n",
        "        self.L2Loss = LpLoss()\n",
        "\n",
        "        # Optimizer\n",
        "        self.opt_init, \\\n",
        "        self.opt_update, \\\n",
        "        self.get_params = complex_adam(exponential_decay(1e-3, \n",
        "                                                         decay_steps=100, \n",
        "                                                         decay_rate=0.99))\n",
        "        self.opt_state = self.opt_init(params)\n",
        "\n",
        "        # Logger\n",
        "        self.itercount = itertools.count()\n",
        "        self.loss_log = []\n",
        "\n",
        "\n",
        "    @partial(jit, static_argnums=0)\n",
        "    def loss(self, params, batch):\n",
        "        inputs, targets = batch\n",
        "        outputs = self.apply(params,inputs)\n",
        "        loss = self.L2Loss(outputs, targets)\n",
        "        return loss    \n",
        "\n",
        "    @partial(jit, static_argnums=0)\n",
        "    def L2error(self, params, batch):\n",
        "        inputs, targets = batch\n",
        "        outputs = self.apply(params,inputs)\n",
        "        error = jnp.linalg.norm(targets.flatten() - outputs.flatten(), 2)/jnp.linalg.norm(targets.flatten(),2)\n",
        "        return error\n",
        "\n",
        "    @partial(jit, static_argnums=(0,))\n",
        "    def step(self, i, opt_state, batch):\n",
        "        params = self.get_params(opt_state)\n",
        "        g = grad(self.loss)(params, batch)\n",
        "        return self.opt_update(i, g, opt_state)\n",
        "\n",
        "    def train(self, dataset, nIter = 10000):\n",
        "        data = iter(dataset)\n",
        "        pbar = trange(nIter)\n",
        "        for it in pbar:\n",
        "            batch = next(data)\n",
        "            self.opt_state = self.step(next(self.itercount), self.opt_state, batch)\n",
        "            # Logger\n",
        "            if it % 100 == 0:\n",
        "                params = self.get_params(self.opt_state)\n",
        "                loss = self.loss(params, batch)\n",
        "                error = self.L2error(params, batch)\n",
        "                self.loss_log.append(loss)\n",
        "                pbar.set_postfix({'Loss': loss, \n",
        "                                  'Relative L2 error': error})\n",
        "\n",
        "    def count_params(self):\n",
        "        params = self.get_params(self.opt_state)\n",
        "        params_flat, _ = ravel_pytree(params)\n",
        "        print(\"The number of model parameters is:\",params_flat.shape[0])"
      ],
      "metadata": {
        "id": "JvscXtvPiVnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model definitions, data loading and parsing\n",
        "\n",
        "In this part, we show how we load the data and pre-process the inputs to the model. \n",
        "\n",
        "We need to load the .npz arrays and then transform them to JAX DeviceArrays from NumPy. Moreover, we need to create a uniform grid for the input parameters and concatenate it together with the input functions."
      ],
      "metadata": {
        "id": "6xIDO-q7__Hi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the problem parameters\n",
        "ntrain = 5000\n",
        "ntest = 5000\n",
        "howmany = ntrain//5\n",
        "\n",
        "batch_size = 100\n",
        "nIter = 50000\n",
        "\n",
        "sub = 8\n",
        "s = 256\n",
        "h = s//sub\n",
        "width = 32\n",
        "modes = 8\n",
        "\n",
        "# Load the training and testing data\n",
        "d = np.load(\"/content/drive/MyDrive/Tripods_Winter_School_2022/train_darcy_dataset.npz\")\n",
        "x_train   = d[\"U_train\"].reshape(ntrain,s,s)[:howmany,::sub,::sub]\n",
        "y_train   = d[\"s_train\"].reshape(ntrain,s,s)[:howmany,::sub,::sub]\n",
        "\n",
        "d = np.load(\"/content/drive/MyDrive/Tripods_Winter_School_2022/test_darcy_dataset.npz\")\n",
        "x_test   = d[\"U_test\"].reshape(ntest,s,s)[:howmany,::sub,::sub]\n",
        "y_test   = d[\"s_test\"].reshape(ntest,s,s)[:howmany,::sub,::sub]\n",
        "\n",
        "grids = []\n",
        "grids.append(np.linspace(0, 1, h))\n",
        "grids.append(np.linspace(0, 1, h))\n",
        "grid = np.vstack([xx.ravel() for xx in np.meshgrid(*grids)]).T\n",
        "grid = grid.reshape(1,h,h,2)\n",
        "x_train = jnp.concatenate((x_train.reshape(howmany,h,h,1), jnp.repeat(grid, howmany,axis=0)), axis=3)\n",
        "\n",
        "x_test = jnp.concatenate((x_test.reshape(howmany,h,h,1), jnp.repeat(grid,howmany,axis=0)), axis=3)\n",
        "x_test = jnp.asarray(x_test)\n",
        "y_test = jnp.asarray(y_test)"
      ],
      "metadata": {
        "id": "8AdCT-4HikfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing the training data\n",
        "\n",
        "At this point, we feed the training data to the DataGenerator class to efficiently sample mini-batches during training."
      ],
      "metadata": {
        "id": "Jied-ExGAfBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the data generator\n",
        "x_train = jnp.asarray(x_train)\n",
        "y_train = jnp.asarray(y_train)\n",
        "\n",
        "train_dataset = DataGenerator(x_train, y_train, batch_size)\n",
        "train_dataset = iter(train_dataset)"
      ],
      "metadata": {
        "id": "txIoeKnxiGj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining the model architecture\n",
        "\n",
        "We define the model architecture, as we explained above and initialize the model:"
      ],
      "metadata": {
        "id": "IVuXBV2iA3dw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the model architecture\n",
        "input_shape = (-1, h, h, 3) # do not commit to a fixed batch size\n",
        "layers = [Dense(width), \n",
        "          Permute(\"ijkl->iljk\"), \n",
        "          FNOBlock2D(h, modes), Gelu,\n",
        "          FNOBlock2D(h, modes), Gelu,\n",
        "          FNOBlock2D(h, modes),\n",
        "          Permute(\"ijkl->iklj\"),\n",
        "          Dense(128), \n",
        "          Gelu,\n",
        "          Dense(1)]"
      ],
      "metadata": {
        "id": "QL5KZndnioSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model class\n",
        "model = FNO(input_shape, layers)\n",
        "model.count_params()"
      ],
      "metadata": {
        "id": "-jqZyV4Ik96X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7a0396c-a958-4989-dfe2-8de63dcea12d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of model parameters is: 400865\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model\n",
        "\n",
        "We train the model and compute the wall-clock time needed for the process to finish"
      ],
      "metadata": {
        "id": "beOUx3yQBCpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "nIter = 10000\n",
        "\n",
        "start_time = timeit.default_timer()\n",
        "model.train(train_dataset, nIter=nIter)\n",
        "elapsed = timeit.default_timer() - start_time\n",
        "print(\"The training wall-clock time is seconds is equal to %f seconds\"%elapsed)"
      ],
      "metadata": {
        "id": "EOLwbphRiwIo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b57a0b2e-6534-4caa-8e6f-9affce34e0d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [02:59<00:00, 55.58it/s, Loss=0.0031011594, Relative L2 error=0.0031350348]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The training wall-clock time is seconds is equal to 179.936275 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Error computation\n",
        "\n",
        "We use the relative $\\mathcal{L}_2$ error between the groundtruth and the predictions to test the accuracy of our model."
      ],
      "metadata": {
        "id": "liwBb2EJBL6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation\n",
        "opt_params = model.get_params(model.opt_state)\n",
        "y_pred = model.apply(opt_params, x_test)\n",
        "\n",
        "test_error_u = []\n",
        "for i in trange(0,ntrain):\n",
        "    error = jnp.linalg.norm(y_test[i,:,:].flatten() - y_pred[i,:,:].flatten(),2)/jnp.linalg.norm(y_test[i,:,:].flatten(),2)\n",
        "    test_error_u.append(error)\n",
        "print(\"The average test u error is %e the standard deviation is %e the min error is %e and the max error is %e\"%(np.mean(test_error_u),\n",
        "                                                                                                                 np.std(test_error_u),\n",
        "                                                                                                                 np.min(test_error_u),\n",
        "                                                                                                                 np.max(test_error_u)))"
      ],
      "metadata": {
        "id": "zRfEElH9iyY2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "437ce13a-a2fe-4a38-abb8-4b54ad93be30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [00:36<00:00, 137.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The average test u error is 2.752264e-03 the standard deviation is 6.417762e-04 the min error is 2.206205e-03 and the max error is 1.271094e-02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save the model parameters \n",
        "\n",
        "We can also save the model parameters for future use"
      ],
      "metadata": {
        "id": "sBNtNAZtBaaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save trained model parameters\n",
        "saveParameters = False\n",
        "if saveParameters:\n",
        "    opt_params_flat, _ = ravel_pytree(opt_params)\n",
        "    np.save(\"FNO_parameters_%dx%d.npy\"%(h,h), opt_params_flat)"
      ],
      "metadata": {
        "id": "V6GcBn_-irt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# END OF THE THIRD TUTORIAL"
      ],
      "metadata": {
        "id": "_DqElJgnBlMi"
      }
    }
  ]
}